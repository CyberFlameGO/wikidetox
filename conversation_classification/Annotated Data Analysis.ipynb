{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ids(df):\n",
    "    conversations = df.values.tolist()\n",
    "    conversation_ids = []\n",
    "    for conv in conversations:\n",
    "        cur_conv = json.loads(conv)\n",
    "        conversation_ids.append(list(cur_conv.keys())[0])\n",
    "    return conversation_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_readable_or_not_sure(df):\n",
    "    df['not_English'] = (df['na'] == True)\n",
    "    df['not_sure_toxicity'] = (df['toxic'] == -1)\n",
    "    non_english = pd.DataFrame({'not_readable': df.groupby('_unit_id')['not_English'].mean() >=0.5}).reset_index()\n",
    "    non_english = non_english[non_english['not_readable'] == True]['_unit_id'].values.tolist()\n",
    "    not_sure_toxicity = pd.DataFrame({'not_sure_toxicity': df.groupby('_unit_id')['not_sure_toxicity'].mean() >= 0.5}).reset_index()\n",
    "    not_sure_toxicity = not_sure_toxicity[not_sure_toxicity['not_sure_toxicity'] == True]['_unit_id'].values.tolist()\n",
    "    return non_english + not_sure_toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOB 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/scratch/wiki_dumps/annotated/job1_constraintsAB_v017.csv') as f:\n",
    "     df = pd.read_csv(f, encoding = 'utf-8', index_col=None, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "toxicity = df[df['toxic'] >= 0]\n",
    "toxic_before = pd.DataFrame({'toxic_before': toxicity.groupby('_unit_id')['toxic'].mean() >= 0.5}).\\\n",
    "            reset_index()\n",
    "toxic_before = toxic_before[toxic_before['toxic_before'] == True]['_unit_id'].values.tolist()\n",
    "_excluded = list(set(non_readable_or_not_sure(df) + toxic_before))\n",
    "annotated = set(get_ids(df['conversations']))\n",
    "excluded_1 = set(get_ids(df[df['_unit_id'].isin(_excluded)]['conversations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each Conversation is annotated by 5~22 workers JOB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOB 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/scratch/wiki_dumps/annotated/job2_constraintsAB_v017.csv') as f:\n",
    "     df = pd.read_csv(f, encoding = 'utf-8', index_col=None, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "_excluded = list(set(non_readable_or_not_sure(df)))\n",
    "excluded_2 = set(get_ids(df[df['_unit_id'].isin(_excluded)]['conversations']))\n",
    "excluded = (excluded_1 | excluded_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['conv_id'] = df.apply(lambda x: list(json.loads(x['conversations']).keys())[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxicity = df[df['toxic'] >= 0]\n",
    "toxic = pd.DataFrame({'toxic': toxicity.groupby('_unit_id')['toxic'].mean() >= 0.5}).reset_index()\n",
    "bad_convs = toxic[toxic['toxic'] == True]['_unit_id'].values.tolist()\n",
    "bad_conversations = set(get_ids(df[df['_unit_id'].isin(bad_convs)]['conversations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['has_disagreement'] = ~(df['disagreement'] == None)\n",
    "disagreement = pd.DataFrame({'disagreement': df.groupby('_unit_id')['has_disagreement'].mean() >= 0.5}).reset_index()\n",
    "disagree_convs = disagreement[disagreement['disagreement'] == True]['_unit_id'].values.tolist()\n",
    "disagree_conversations = set(get_ids(df[df['_unit_id'].isin(disagree_convs)]['conversations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_and_disagree = (bad_conversations & disagree_conversations - excluded)\n",
    "good_and_disagree = (disagree_conversations - bad_conversations - excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attacker_in_conv(conv):\n",
    "    actions = conv['action_feature']\n",
    "    end_time = max([a['timestamp_in_sec'] for a in actions])\n",
    "    attacker = None\n",
    "    for a in actions:\n",
    "        if a['timestamp_in_sec'] == end_time:\n",
    "            attacker = a['user_text']\n",
    "    for a in actions:\n",
    "        if a['timestamp_in_sec'] < end_time and a['user_text'] == attacker:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods = {}\n",
    "bads = []\n",
    "all_data = {}\n",
    "included = {}\n",
    "with open('/scratch/wiki_dumps/expr_with_matching/delta2_no_users_attacker_in_conv/data/all.json') as f:\n",
    "    for line in f:\n",
    "        conv_id, clss, conversation = json.loads(line)\n",
    "        if conv_id in all_data:\n",
    "            continue\n",
    "        all_data[conv_id] = [conv_id, clss, conversation]\n",
    "        if clss == 0 and (attacker_in_conv(all_data[conversation['action_feature'][0]['good_conversation_id']][2])):\n",
    "            bads.append([conv_id, clss, conversation])\n",
    "            goods[conv_id] = all_data[conversation['action_feature'][0]['good_conversation_id']]\n",
    "cleaned_data = bads + list(goods.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5078"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "bad_disagree = []\n",
    "good_disagree = []\n",
    "xs = []\n",
    "total_bad = 0\n",
    "total_good = 0\n",
    "for line in cleaned_data:\n",
    "    conv_id, clss, conversation = line\n",
    "    idlist = [k['id'] for k in conversation['action_feature']]\n",
    "    is_annotated = not(annotated.isdisjoint(idlist))\n",
    "    is_excluded = not(excluded.isdisjoint(idlist))\n",
    "    is_bd = not(bad_and_disagree.isdisjoint(idlist))\n",
    "    is_gd = not(good_and_disagree.isdisjoint(idlist))\n",
    "    annotated_class = bad_conversations.isdisjoint(idlist)\n",
    "    same_class = (int(annotated_class) == clss)\n",
    "    if 'good_conversation_id' in conversation['action_feature'][0]:\n",
    "        matched_id = conversation['action_feature'][0]['good_conversation_id']\n",
    "    else:\n",
    "        matched_id = conversation['action_feature'][0]['bad_conversation_id']\n",
    "    dt = {'conversation_id': conv_id, 'annotated': is_annotated, 'excluded': is_excluded, \\\n",
    "        'annotated_class': annotated_class, 'class': clss, 'matched_id': matched_id, 'same_class': same_class}\n",
    "    if is_bd and not(is_excluded) and is_annotated:\n",
    "        bad_disagree.append(dt)\n",
    "    if is_gd and not(is_excluded):\n",
    "        good_disagree.append(dt)\n",
    "    if annotated_class:\n",
    "        total_good += 1\n",
    "    else:total_bad += 1\n",
    "    data.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad conversations with disagreement : 1291\n",
      "Total Number of bad conversations: 1334\n",
      "Number of good conversations with disagreement : 2897\n",
      "Total Number of bad conversations: 3744\n",
      "Good conversations with disagreement / good conversations: 0.7737713675213675\n",
      "Bad conversations with disagreement / bad conversations: 0.9677661169415293\n",
      "Bad conversations with disagreement / all conversations with disagreement 0.30826170009551096\n",
      "Number of bad conversations / all conversations: 0.26270185112248917\n"
     ]
    }
   ],
   "source": [
    "bad_but_disagree = pd.DataFrame(bad_disagree)\n",
    "good_but_disagree = pd.DataFrame(good_disagree)\n",
    "print('Number of bad conversations with disagreement :', len(bad_but_disagree))\n",
    "print('Total Number of bad conversations:', total_bad)\n",
    "print('Number of good conversations with disagreement :', len(good_but_disagree))\n",
    "print('Total Number of bad conversations:', total_good)\n",
    "print('Good conversations with disagreement / good conversations:', len(good_but_disagree) / total_good)\n",
    "print('Bad conversations with disagreement / bad conversations:', len(bad_but_disagree) / total_bad)\n",
    "print('Bad conversations with disagreement / all conversations with disagreement', len(bad_but_disagree) / (len(good_but_disagree) + len(bad_but_disagree)))\n",
    "print('Number of bad conversations / all conversations:', total_bad/(total_bad+total_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3602\n",
      "4744\n",
      "0.7592748735244519\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31650853889943076"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1668/(1668+3602) # toxic&disagree / all disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2660891089108911"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1720/(1720+4744) # toxic / all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Conversations Annotated: 4306\n",
      "Number of Conversations Excluded: 118\n",
      "Number of Conversations left: 2066\n"
     ]
    }
   ],
   "source": [
    "annotation_aggregated = pd.DataFrame(data)\n",
    "print('Number of Conversations Annotated:', len(annotation_aggregated[annotation_aggregated['annotated'] == True]))\n",
    "print('Number of Conversations Excluded:', len(annotation_aggregated[annotation_aggregated['excluded'] == True]))\n",
    "annotation_aggregated = annotation_aggregated[(annotation_aggregated['annotated'] == True)\\\n",
    "                                              & (annotation_aggregated['excluded'] == False)\\\n",
    "                                              & (annotation_aggregated['same_class'] == True)]\n",
    "left_ids = annotation_aggregated['conversation_id'].values.tolist()\n",
    "annotation_aggregated = annotation_aggregated[annotation_aggregated['matched_id'].isin(left_ids)]\n",
    "print('Number of Conversations left:', len(annotation_aggregated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verified_pairs = annotation_aggregated['conversation_id'].values.tolist()\n",
    "goods = {}\n",
    "bads = []\n",
    "all_data = {}\n",
    "with open('/scratch/wiki_dumps/expr_with_matching/delta2_no_users_attacker_in_conv/data/all_verified.json', 'w') as w:\n",
    "    with open('/scratch/wiki_dumps/expr_with_matching/delta2_no_users_attacker_in_conv/data/all.json') as f:\n",
    "        for line in f:\n",
    "            conv_id, clss, conversation = json.loads(line)\n",
    "            if conv_id in verified_pairs:\n",
    "                w.write(json.dumps([conv_id, clss, conversation]) + '\\n')\n",
    "                all_data[conv_id] = [conv_id, clss, conversation]\n",
    "                if clss == 0:\n",
    "                    bads.append([conv_id, clss, conversation])\n",
    "                    goods[conv_id] = all_data[conversation['action_feature'][0]['good_conversation_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotator Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOXIC_COLUMNS = ['no_toxic', 'toxic']\n",
    "\n",
    "no_toxic = pd.DataFrame({'no_toxic': df[df['toxic'] == 0].groupby('_unit_id').size()}).reset_index().set_index('_unit_id')\n",
    "toxic = pd.DataFrame({'toxic': df[df['toxic'] == 1].groupby('_unit_id').size()}).reset_index().set_index('_unit_id')\n",
    "total = toxic.join(no_toxic, how='outer')\n",
    "total = total.fillna(int(0)).reset_index()\n",
    "total['sum'] = total['toxic'] + total['no_toxic']\n",
    "#total = total[total['sum'] ==20]\n",
    "\n",
    "len(total[total['sum'] >=20]) / len(total)\n",
    "\n",
    "total = total[total['sum'] == 5]\n",
    "\n",
    "total['toxic'] = total.apply(lambda x: int(x['toxic']), axis=1)\n",
    "\n",
    "total['sum'] = total['toxic'] + total['no_toxic']\n",
    "\n",
    "total[['sum']].plot.hist\n",
    "\n",
    "n,bins,batches = plt.hist(total['no_toxic'])\n",
    "\n",
    "len(total[total['no_toxic'] > 20]) / len(total)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "total = total[~(total['_unit_id'].isin(_excluded))]\n",
    "\n",
    "print(len(total), Krippendorf_alpha(total, TOXIC_COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2643 0.282819056548\n"
     ]
    }
   ],
   "source": [
    "TOXIC_COLUMNS = ['no_toxic', 'toxic']\n",
    "\n",
    "no_toxic = pd.DataFrame({'no_toxic': df[df['toxic'] == 0].groupby('_unit_id').size()}).reset_index().set_index('_unit_id')\n",
    "toxic = pd.DataFrame({'toxic': df[df['toxic'] == 1].groupby('_unit_id').size()}).reset_index().set_index('_unit_id')\n",
    "total = toxic.join(no_toxic, how='outer')\n",
    "total = total.fillna(0).reset_index()\n",
    "total['sum'] = total['toxic'] + total['no_toxic']\n",
    "total = total[total['sum'] ==20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
