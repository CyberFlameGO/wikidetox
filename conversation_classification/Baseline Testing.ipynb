{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as cPickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNIGRAMS_FILENAME = \"bow_features/unigram20.pkl\"\n",
    "BIGRAMS_FILENAME = \"bow_features/bigram50.pkl\"\n",
    "UNIGRAMS_LIST = cPickle.load(open(UNIGRAMS_FILENAME, \"rb\"))\n",
    "BIGRAMS_LIST = cPickle.load(open(BIGRAMS_FILENAME, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('feature_extraction/lexicons') as f:\n",
    "    LEXICONS = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features(document):\n",
    "    feature_dict = {}\n",
    "    feature_dict.update(_get_term_features(document))\n",
    "    feature_dict.update(_get_action_features(document))\n",
    "    return feature_dict\n",
    "\n",
    "def _get_term_features(document):\n",
    "    actions = document['action_feature']\n",
    "    unigrams, bigrams = set([]), set([])\n",
    "    end_time = 0\n",
    "    for action in actions:\n",
    "        if action['timestamp_in_sec'] > end_time:\n",
    "            end_time = action['timestamp_in_sec'] \n",
    "    for action in actions:\n",
    "        if action['timestamp_in_sec'] == end_time or \\\n",
    "            not(action['comment_type'] == 'COMMENT_ADDING' or\\\n",
    "                action['comment_type'] == 'SECTION_CREATION' or\\\n",
    "                action['comment_type'] == 'COMMENT_MODIFICATION'):\n",
    "            continue\n",
    "        unigrams = unigrams | set(action['unigrams'])\n",
    "        bigrams = bigrams | set([tuple(x) for x in action['bigrams']]) \n",
    "    f = {}\n",
    "    f.update(dict(map(lambda x: (\"UNIGRAM_\" + str(x), 1 if x in unigrams else 0), UNIGRAMS_LIST)))\n",
    "    f.update(dict(map(lambda x: (\"BIGRAM_\" + str(x), 1 if tuple(x) in bigrams else 0), BIGRAMS_LIST)))\n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_action_features(document):\n",
    "    # polarity, politeness --> max, min\n",
    "    # length --> max, min\n",
    "    # has_agree, has_disagree \n",
    "    \n",
    "    # based on user --> balance among users(avg of each feature)\n",
    "    \n",
    "    # pronoun usage\n",
    "    \n",
    "    # lexicon ratio\n",
    "    actions = document['action_feature']\n",
    "    unigrams, bigrams = set([]), set([])\n",
    "    end_time = 0\n",
    "    for action in actions:\n",
    "        if action['timestamp_in_sec'] > end_time:\n",
    "            end_time = action['timestamp_in_sec'] \n",
    "    ret = {'max_polarity': -1, 'min_polarity': 1, 'max_politeness': 0, 'min_politeness': 1, 'max_length': 0, \\\n",
    "        'min_length': 1000000}\n",
    "    for key in LEXICONS.keys():\n",
    "        ret[key] = 0\n",
    "    ret['length'] = 0\n",
    "    has_politeness = False\n",
    "    for action in actions:\n",
    "        if action['timestamp_in_sec'] == end_time or \\\n",
    "            not(action['comment_type'] == 'COMMENT_ADDING' or\\\n",
    "                action['comment_type'] == 'SECTION_CREATION' or\\\n",
    "                action['comment_type'] == 'COMMENT_MODIFICATION'):\n",
    "            continue\n",
    "        # Polarity\n",
    "        polarity = []\n",
    "        for p in action['polarity']:\n",
    "            polarity.append(p['compound'])\n",
    "        ret['max_polarity'] = max(ret['max_polarity'], np.average(polarity))\n",
    "        ret['min_polarity'] = min(ret['min_polarity'], np.average(polarity))\n",
    "\n",
    "        \n",
    "        # Politeness\n",
    "        if action['is_request']:\n",
    "            ret['max_politeness'] = max(ret['max_politeness'], action['politeness_score']['polite'])\n",
    "            ret['min_politeness'] = min(ret['min_politeness'], action['politeness_score']['polite'])\n",
    "            has_politeness = True\n",
    "        \n",
    "        # Pronoun\n",
    "        for key in LEXICONS.keys():\n",
    "            ret[key] += action[key]\n",
    "            \n",
    "        ret['length'] += action['length'] \n",
    "        ret['max_length'] = max(ret['max_length'], action['length'])\n",
    "        ret['min_length'] = min(ret['min_length'], action['length'])\n",
    "\n",
    "    for key in LEXICONS.keys():\n",
    "        ret[key] /= ret['length']\n",
    "    if not(has_politeness):\n",
    "        ret['max_politeness'] = ret['min_politeness'] = 0.5\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def documents2feature_vectors(documents):\n",
    "    fks = False\n",
    "    X, y = [], []\n",
    "    cnt = 0\n",
    "    for pair in documents:\n",
    "        conversation, clss = pair\n",
    "        fs = features(conversation)\n",
    "        if not fks:\n",
    "            fks = sorted(fs.keys())\n",
    "        fv = [fs[f] for f in fks]\n",
    "        if cnt % 1000 == 0:\n",
    "            print(cnt)\n",
    "        cnt += 1\n",
    "        X.append(fv)\n",
    "        y.append(clss)\n",
    "    X = csr_matrix(np.asarray(X))\n",
    "    y = np.asarray(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_svm(X, y):\n",
    "\n",
    "    # For good luck\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    tuned_parameters = [#{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "                    {'C': [0.0002, 0.0003, 0.0004, 0.00045]}]\n",
    "\n",
    "    clf = GridSearchCV(svm.LinearSVC(), tuned_parameters, cv=5, scoring = 'accuracy')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_estimator_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() / 2, params))\n",
    "    print()\n",
    "\n",
    "#    print(scores.mean())\n",
    "#    print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "with open('/scratch/wiki_dumps/train_test/train.json') as f:\n",
    "    for line in f:\n",
    "        conv_id, clss, conversation = json.loads(line)\n",
    "        documents.append((conversation, clss))       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "176208    unigram total                                                                                               \n",
    "1354891   bigram total \n",
    "UNIGRAM:\n",
    "15324     10                                                                                                  \n",
    "11853   15                                                                                              \n",
    "9826    20                                                                                                    \n",
    "5386    50                                                                                                    \n",
    "3354    100\n",
    "\n",
    "BIGRAM\n",
    "55380  10                                                                                                      \n",
    "30036  20                                                                                                     \n",
    "12967  50                                                                                                    \n",
    "6613   100                                                                                                     \n",
    "1130   500\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C = 0.00075\n",
    "# 57.6%\n",
    "# unigram50, bigram100\n",
    "\n",
    "# C = 0.00075\n",
    "# 57.4%\n",
    "# unigram100, bigram100\n",
    "\n",
    "# C = 0.00075\n",
    "# 57.4%\n",
    "# unigram50, bigram500\n",
    "\n",
    "# C= 0.0006\n",
    "# 58%\n",
    "# unigram20, bigram100\n",
    "\n",
    "# 0.581 (+/-0.003) for {'C': 0.0004}\n",
    "# unigram20, bigram50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2008-11-27 19:34:14 UTC', '2008-11-27 16:43:21 UTC', '2008-11-27 16:43:21 UTC', '2008-11-27 18:29:48 UTC', '2008-11-27 18:31:23 UTC']\n",
      "True\n",
      "0\n",
      "['2014-06-23 16:14:32 UTC', '2014-06-23 16:14:32 UTC', '2014-06-23 16:15:42 UTC']\n",
      "True\n",
      "['2010-01-14 02:02:55 UTC', '2010-01-14 02:02:55 UTC', '2010-02-03 00:09:51 UTC', '2010-02-03 00:08:52 UTC', '2010-01-14 02:03:39 UTC']\n",
      "True\n",
      "['2011-10-16 10:07:59 UTC', '2010-09-30 14:12:50 UTC', '2010-09-30 14:12:50 UTC']\n",
      "False\n",
      "['2008-08-27 14:43:27 UTC', '2008-08-26 16:53:27 UTC', '2008-08-26 14:42:13 UTC', '2008-08-26 19:32:41 UTC', '2008-08-26 16:31:59 UTC', '2008-08-26 15:27:37 UTC', '2008-08-27 14:43:27 UTC', '2008-08-26 14:42:13 UTC']\n",
      "True\n",
      "['2007-04-30 19:20:36 UTC', '2007-05-01 01:46:06 UTC', '2007-04-30 19:20:36 UTC']\n",
      "False\n",
      "['2009-06-07 17:27:20 UTC', '2009-06-07 17:27:20 UTC', '2009-06-07 17:27:20 UTC', '2009-06-07 17:27:20 UTC', '2009-06-07 17:27:20 UTC', '2009-06-07 17:27:20 UTC', '2009-06-07 17:27:20 UTC', '2009-06-07 17:27:20 UTC', '2009-06-07 17:27:20 UTC', '2009-06-07 17:27:20 UTC', '2009-06-07 17:27:20 UTC']\n",
      "True\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-52e002010084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocuments2feature_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-fd99eac4d77e>\u001b[0m in \u001b[0;36mdocuments2feature_vectors\u001b[0;34m(documents)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mconversation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mfks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-60833b834973>\u001b[0m in \u001b[0;36mfeatures\u001b[0;34m(document)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfeature_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeature_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_term_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfeature_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_action_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-42b67e684f1e>\u001b[0m in \u001b[0;36m_get_action_features\u001b[0;34m(document)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bad_length'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mLEXICONS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhas_politeness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_politeness'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_politeness'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "random.shuffle(documents)\n",
    "X, y = documents2feature_vectors(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Best parameters set found on development set:\n",
      "\n",
      "LinearSVC(C=0.0004, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.569 (+/-0.007) for {'C': 0.0002}\n",
      "0.574 (+/-0.006) for {'C': 0.0003}\n",
      "0.581 (+/-0.003) for {'C': 0.0004}\n",
      "0.579 (+/-0.003) for {'C': 0.00045}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiqing/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_svm(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Best parameters set found on development set:\n",
      "\n",
      "LinearSVC(C=0.005, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.558 (+/-0.002) for {'C': 0.01}\n",
      "0.555 (+/-0.002) for {'C': 0.015}\n",
      "0.564 (+/-0.002) for {'C': 0.005}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiqing/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_svm(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Best parameters set found on development set:\n",
      "\n",
      "LinearSVC(C=0.0025, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.565 (+/-0.001) for {'C': 0.0001}\n",
      "0.569 (+/-0.003) for {'C': 0.0025}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiqing/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_svm(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Best parameters set found on development set:\n",
      "\n",
      "LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.573 (+/-0.002) for {'C': 0.001}\n",
      "0.569 (+/-0.002) for {'C': 0.002}\n",
      "0.567 (+/-0.003) for {'C': 0.003}\n",
      "0.565 (+/-0.002) for {'C': 0.004}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiqing/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_svm(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Best parameters set found on development set:\n",
      "\n",
      "LinearSVC(C=0.00075, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.574 (+/-0.005) for {'C': 0.0005}\n",
      "0.576 (+/-0.002) for {'C': 0.00075}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiqing/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_svm(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Best parameters set found on development set:\n",
      "\n",
      "LinearSVC(C=0.0008, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.575 (+/-0.002) for {'C': 0.0008}\n",
      "0.574 (+/-0.002) for {'C': 0.0009}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiqing/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_svm(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
